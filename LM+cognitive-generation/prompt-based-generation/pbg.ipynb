{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9eb6100",
   "metadata": {},
   "source": [
    "# Prompt-Based Synthetic Data Generation (MVP)\n",
    "\n",
    "**Project:** Synthetic Data Creation: Survey and Synthesis  \n",
    "**Method Group:** Language-Model and Cognitive Generation  \n",
    "**Sub-method:** Prompt-Based Generation  \n",
    "**Author:** Prajna Penmetsa \n",
    "\n",
    "**Goal:**  \n",
    "Use Gemini API to generate small, reproducible synthetic learning datasets (e.g., quiz questions, student responses, or explanations) to demonstrate prompt-based synthetic data creation for learning middleware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa72078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GEMINI_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, json, requests, time\n",
    "\n",
    "# Load .env file (should contain: GEMINI_API_KEY=<your_key>)\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"❌ GEMINI_API_KEY not found. Please check .env file.\")\n",
    "else:\n",
    "    print(\"✅ GEMINI_API_KEY loaded successfully.\")\n",
    "\n",
    "# --- Model + Endpoint (latest available for your key) ---\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{MODEL}:generateContent?key={API_KEY}\"\n",
    "\n",
    "# Output directory\n",
    "os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ad11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200 | Time: 2.24 s\n",
      "✅ Connected successfully.\n",
      "Response: Hello there!\n"
     ]
    }
   ],
   "source": [
    "payload = {\"contents\": [{\"parts\": [{\"text\": \"Say hello in one sentence.\"}]}]}\n",
    "\n",
    "t0 = time.time()\n",
    "r = requests.post(GEMINI_URL, json=payload)\n",
    "print(\"Status:\", r.status_code, \"| Time:\", round(time.time() - t0, 2), \"s\")\n",
    "\n",
    "if r.ok:\n",
    "    data = r.json()\n",
    "    text = data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    print(\"✅ Connected successfully.\\nResponse:\", text)\n",
    "else:\n",
    "    print(\"❌ Error:\", r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f52cd",
   "metadata": {},
   "source": [
    "### Prompt Design\n",
    "\n",
    "We will generate **10 math word problems** for middle school students, each with:\n",
    "\n",
    "1. A question text  \n",
    "2. Four options labeled A, B, C, and D  \n",
    "3. The correct answer key (A/B/C/D)  \n",
    "\n",
    "The model will output a **valid JSON list** for easy parsing and benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "108e795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200 | Time: 13.84 s\n",
      "[\n",
      "  {\n",
      "    \"question\": \"Sarah bought a new bicycle that was originally priced at $240. If it was on sale for 25% off, what was the discounted price of the bicycle?\",\n",
      "    \"options\": {\"A\": \"$180\", \"B\": \"$60\", \"C\": \"$160\", \"D\": \"$200\"},\n",
      "    \"answer\": \"A\"\n",
      "  },\n",
      "  {\n",
      "    \"question\": \"A baker used 3/4 cup of flour for one recipe and 1/2 cup of flour for another recipe. How much flour did the baker use in total?\",\n",
      "    \"options\": {\"A\": \"1 cup\", \"B\": \"1 1/4 cups\", \"C\": \"1 1/2 cups\", \"D\": \"3/8 cup\"},\n",
      "    \"an\n"
     ]
    }
   ],
   "source": [
    "prompt_text = \"\"\"\n",
    "You are an educational content creator.\n",
    "Generate 10 math word problems for middle school students.\n",
    "Each problem must include:\n",
    "1. The question text.\n",
    "2. Four answer options labeled A, B, C, and D.\n",
    "3. The correct answer key (A/B/C/D).\n",
    "Return only the JSON array. No explanations, markdown, or commentary.\n",
    "Format exactly like this example:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"question\": \"A train travels 60 km in 1.5 hours. What is its speed?\",\n",
    "    \"options\": {\"A\": \"30 km/h\", \"B\": \"40 km/h\", \"C\": \"50 km/h\", \"D\": \"60 km/h\"},\n",
    "    \"answer\": \"C\"\n",
    "  }\n",
    "]\n",
    "Now generate 10 new, unique questions.\n",
    "\"\"\"\n",
    "\n",
    "payload = {\"contents\": [{\"parts\": [{\"text\": prompt_text}]}]}\n",
    "\n",
    "t0 = time.time()\n",
    "r = requests.post(GEMINI_URL, json=payload)\n",
    "print(\"Status:\", r.status_code, \"| Time:\", round(time.time() - t0, 2), \"s\")\n",
    "\n",
    "if not r.ok:\n",
    "    raise RuntimeError(f\"❌ Generation failed: {r.text}\")\n",
    "\n",
    "generated = r.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "print(generated[:500])  # preview first 500 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22d4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved raw output to outputs/synthetic_questions_raw.txt\n",
      "✅ JSON parsed successfully. Sample:\n",
      "1. Sarah bought a new bicycle that was originally priced at $240. If it was on sale for 25% off, what was the discounted price of the bicycle? → A\n",
      "2. A baker used 3/4 cup of flour for one recipe and 1/2 cup of flour for another recipe. How much flour did the baker use in total? → B\n",
      "✅ Saved clean JSON to outputs/synthetic_questions.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Save raw output\n",
    "raw_path = \"outputs/synthetic_questions_raw.txt\"\n",
    "with open(raw_path, \"w\") as f:\n",
    "    f.write(generated)\n",
    "print(f\"✅ Saved raw output to {raw_path}\")\n",
    "\n",
    "# --- Robust JSON extraction ---\n",
    "json_pattern = re.compile(r\"\\[.*\\]\", re.DOTALL)\n",
    "match = json_pattern.search(generated)\n",
    "\n",
    "if match:\n",
    "    json_text = match.group(0)\n",
    "    try:\n",
    "        data = json.loads(json_text)\n",
    "        print(\"✅ JSON parsed successfully. Sample:\")\n",
    "        for i, q in enumerate(data[:2]):\n",
    "            print(f\"{i+1}. {q['question']} → {q['answer']}\")\n",
    "        with open(\"outputs/synthetic_questions.json\", \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(\"✅ Saved clean JSON to outputs/synthetic_questions.json\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Parsing failed after extraction:\", e)\n",
    "else:\n",
    "    print(\"❌ No JSON-like block detected in model output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db330f",
   "metadata": {},
   "source": [
    "### Quick Evaluation Checklist\n",
    "We’ll check for:\n",
    "- Structural validity (question, options, answer present)\n",
    "- Diversity of questions\n",
    "- Coherence and logical correctness (manual inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "732720f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Structure valid for all entries\n",
      "Total generated questions: 10\n"
     ]
    }
   ],
   "source": [
    "if \"data\" in locals():\n",
    "    valid = all(\"question\" in q and \"options\" in q and \"answer\" in q for q in data)\n",
    "    print(\"✅ Structure valid for all entries\" if valid else \"⚠️ Some entries missing fields\")\n",
    "    print(f\"Total generated questions: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6e486",
   "metadata": {},
   "source": [
    "### Observations & Analysis (From Generated Output)\n",
    "\n",
    "The prompt-based generation using **Gemini 2.5 Flash** produced ten math word problems that were:\n",
    "\n",
    "**1. Coherent and Logically Sound**  \n",
    "- Every question had correct numerical reasoning (percentages, ratios, averages, etc.).  \n",
    "- Answers aligned properly with each question’s logic.  \n",
    "- Example: *“Sarah bought a bicycle for $240 at 25% off” → $180 was correct.*\n",
    "\n",
    "**2. Diverse in Topic Coverage**  \n",
    "- Covered a range of middle-school math skills:  \n",
    "  - Arithmetic (addition, ratios, averages)  \n",
    "  - Geometry (area, volume)  \n",
    "  - Algebraic reasoning (variable solving)  \n",
    "  - Everyday math (scales, discounts, temperature changes)\n",
    "\n",
    "**3. Pedagogically Appropriate**  \n",
    "- Language was clear and grade-level appropriate.  \n",
    "- Each problem involved realistic, interpretable scenarios.  \n",
    "- Balanced use of units (km, °F, $, cups).\n",
    "\n",
    "**4. Structural Integrity**  \n",
    "- All entries followed the requested JSON format without extra text.  \n",
    "- Each item contained exactly 3 fields: `question`, `options`, `answer`.  \n",
    "- Parsing succeeded automatically after regex cleanup.\n",
    "\n",
    "**5. Evaluation Summary**  \n",
    "| Metric | Observation |\n",
    "|:--|:--|\n",
    "| Fidelity | High – no factual or logical inconsistencies detected. |\n",
    "| Diversity | Good – topics spanned different math domains. |\n",
    "| Structure | Excellent – fully consistent JSON output. |\n",
    "| Pedagogical value | Strong – readable and relevant for learning middleware. |\n",
    "\n",
    "**6. Next Steps / Improvements**  \n",
    "- Introduce *metadata fields* (e.g., topic, difficulty).  \n",
    "- Extend to multi-subject domains (science, reading comprehension).  \n",
    "- Add automated evaluation scripts to check numerical accuracy.  \n",
    "- Explore controlled prompt variants to generate graded difficulty levels.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion:**  \n",
    "This run validates that prompt-based generation with Gemini 2.5 Flash is a reliable and high-quality method for producing structured educational datasets.  \n",
    "It successfully meets fidelity, diversity, and format requirements for integration into synthetic learning middleware pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19048a2",
   "metadata": {},
   "source": [
    "### Run Metadata\n",
    "- Date: October 24th, 2025  \n",
    "- Model: `gemini-2.5-flash`  \n",
    "- Endpoint: `v1beta REST API`  \n",
    "- Temperature: default (~0.9)  \n",
    "- Output Files:  \n",
    "  - `outputs/synthetic_questions_raw.txt`  \n",
    "  - `outputs/synthetic_questions.json`  \n",
    "- Author: Prajna Penmetsa  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
