{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cae7670",
   "metadata": {},
   "source": [
    "# Self-Instruct Pipelines (MVP)\n",
    "\n",
    "**Project:** Synthetic Data Creation: Survey and Synthesis  \n",
    "**Method Group:** Language-Model and Cognitive Generation  \n",
    "**Sub-method:** Self-Instruct Pipelines  \n",
    "**Author:** Prajna Penmetsa\n",
    "\n",
    "**Goal:**  Implement an iterative synthetic-data generation pipeline in which a language model produces and refines its own **instruction–response** datasets.  \n",
    "- Using the Gemini 2.5 Flash REST API, the model begins with a few manually provided *seed examples*, expands them into new tasks and solutions, and repeats this process across multiple rounds.  \n",
    "- This demonstrates how self-instruct pipelines can improve dataset diversity and quality for learning middleware applications without manual labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa36344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, json, requests, time, random\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "GEMINI_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{MODEL}:generateContent?key={API_KEY}\"\n",
    "\n",
    "os.makedirs(\"outputs/sip\", exist_ok=True)\n",
    "\n",
    "def call_gemini(prompt_text):\n",
    "    payload = {\"contents\":[{\"parts\":[{\"text\":prompt_text}]}]}\n",
    "    r = requests.post(GEMINI_URL, json=payload)\n",
    "    if r.ok:\n",
    "        return r.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"❌ Error:\", r.status_code, r.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6caa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed examples: 4\n"
     ]
    }
   ],
   "source": [
    "seed_examples = [\n",
    "    {\"instruction\": \"Solve for x: 3x + 9 = 21\", \n",
    "     \"response\": \"Subtract 9 → 3x = 12 → x = 4.\"},\n",
    "    {\"instruction\": \"Explain photosynthesis in one sentence.\", \n",
    "     \"response\": \"Plants convert sunlight, carbon dioxide, and water into glucose and oxygen.\"},\n",
    "    {\"instruction\": \"Translate 'Good morning' to Spanish.\", \n",
    "     \"response\": \"'Buenos días'.\"},\n",
    "    {\"instruction\": \"Find the perimeter of a square with side 8 cm.\", \n",
    "     \"response\": \"Perimeter = 4 × 8 = 32 cm.\"},\n",
    "]\n",
    "print(f\"Seed examples: {len(seed_examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c5d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meta_prompt(examples, n_new=5):\n",
    "    sample_text = json.dumps(examples, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "You are a dataset generator improving your own instruction set.\n",
    "Below are example instruction–response pairs.\n",
    "\n",
    "{sample_text}\n",
    "\n",
    "Generate {n_new} new, diverse, high-quality pairs that follow the same JSON format:\n",
    "[\n",
    "  {{\n",
    "    \"instruction\": \"...\",\n",
    "    \"response\": \"...\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Output only the JSON array. No commentary or markdown.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142a07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Round 1 ===\n",
      "✅ Added 5 new examples. Total now: 9\n",
      "\n",
      "=== Round 2 ===\n",
      "✅ Added 5 new examples. Total now: 14\n",
      "\n",
      "=== Round 3 ===\n",
      "✅ Added 5 new examples. Total now: 19\n",
      "\n",
      "✅ Saved full dataset with 19 examples.\n"
     ]
    }
   ],
   "source": [
    "all_data = seed_examples.copy()\n",
    "num_rounds = 3\n",
    "n_per_round = 5\n",
    "\n",
    "for round_i in range(num_rounds):\n",
    "    print(f\"\\n=== Round {round_i+1} ===\")\n",
    "    prompt = make_meta_prompt(random.sample(all_data, min(5, len(all_data))), n_new=n_per_round)\n",
    "    gen_text = call_gemini(prompt)\n",
    "    if not gen_text:\n",
    "        continue\n",
    "    # Extract JSON block\n",
    "    import re\n",
    "    match = re.search(r\"\\[.*\\]\", gen_text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            new_items = json.loads(match.group(0))\n",
    "            all_data.extend(new_items)\n",
    "            print(f\"✅ Added {len(new_items)} new examples. Total now: {len(all_data)}\")\n",
    "        except Exception as e:\n",
    "            print(\"⚠️ Parse error:\", e)\n",
    "    else:\n",
    "        print(\"⚠️ No JSON found in response.\")\n",
    "\n",
    "# Save dataset\n",
    "with open(\"outputs/self_instruct_dataset.json\", \"w\") as f:\n",
    "    json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"\\n✅ Saved full dataset with {len(all_data)} examples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358a4db",
   "metadata": {},
   "source": [
    "### Observations & Reflection (From Generated Output)\n",
    "\n",
    "The self-instruct pipeline using **Gemini 2.5 Flash** successfully produced a diverse, high-quality set of instruction–response pairs across multiple subject areas.\n",
    "\n",
    "**1. Structural and Format Quality**  \n",
    "- Every entry strictly followed the required JSON schema (`instruction`, `response`).  \n",
    "- Responses were concise and aligned directly with the question intent.  \n",
    "- No invalid or empty fields were detected.\n",
    "\n",
    "**2. Diversity and Domain Spread**  \n",
    "- Tasks spanned math (algebra, geometry, units), science (photosynthesis, supernova, human heart), language (translation, spelling, grammar), and general knowledge (capitals, leap year).  \n",
    "- This shows effective generalization beyond the initial seed examples.  \n",
    "\n",
    "**3. Pedagogical Strength**  \n",
    "- Questions were simple, factual, and clear enough for middle-school or general-knowledge learning contexts.  \n",
    "- Responses were short, direct, and suitable for automated tutoring or curriculum generation.  \n",
    "\n",
    "**4. Fidelity and Correctness**  \n",
    "- All mathematical computations and factual statements were correct.  \n",
    "- Example: *3x – 7 = 11 → x = 6* and *25 °C → 77 °F* verified accurate.  \n",
    "- No hallucinations or off-topic outputs observed.  \n",
    "\n",
    "**5. Evaluation Summary**\n",
    "\n",
    "| Metric | Observation |\n",
    "|:--|:--|\n",
    "| Structural fidelity | Excellent – consistent JSON output |\n",
    "| Content accuracy | High – correct and verifiable responses |\n",
    "| Diversity | Strong – multiple subjects and skills |\n",
    "| Pedagogical clarity | High – readable, age-appropriate phrasing |\n",
    "\n",
    "**6. Overall Insight**  \n",
    "The SIP method effectively expanded a small seed set into a broader, balanced dataset without manual authoring.  \n",
    "It demonstrates the ability of large language models to *self-bootstrap* instructional data that can later be filtered, tagged by difficulty, or fine-tuned for adaptive learning systems.\n",
    "\n",
    "**Next Steps**  \n",
    "- Add quality-filtering heuristics (remove duplicates, flag too-short responses).  \n",
    "- Annotate domain and difficulty metadata for each pair.  \n",
    "- Iterate for more rounds to grow dataset size and complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d66a9",
   "metadata": {},
   "source": [
    "### Run Metadata\n",
    "- Date: October 24th, 2025  \n",
    "- Model: `gemini-2.5-flash`  \n",
    "- Endpoint: `v1beta REST API`  \n",
    "- Iterations: 3 rounds × 5 new examples per round  \n",
    "- Total Output Examples: ≈ 20 (seeds + generated)  \n",
    "- Output File: `outputs/self_instruct_dataset.json`  \n",
    "- Temperature: default (~0.9)  \n",
    "- Author: Prajna Penmetsa  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
